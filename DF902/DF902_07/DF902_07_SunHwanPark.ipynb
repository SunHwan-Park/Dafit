{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF902_SunHwanPark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Dense 레이어\n",
    "#- 인공신경망 모형에 입력과 출력이 모두 연결된 은닉층(들)과, 출력층을 생성한다.(add 함수로 모델에 추가)\n",
    "#\t* 주요 파라미터\n",
    "#\t- units: 해당 층에 배치할 노드 수\n",
    "#\t- input_dim: 입력 특성의 수, 즉 입력 노드의 개수이다.(최초 은닉층 외에는 기재 X)\n",
    "#\t- kernel_initializer: 가중치들의 초기화, 설정 방법.\n",
    "#\t- activation: 활성화 함수.\n",
    "\n",
    "#2. Flatten 레이어\n",
    "#- 인공신경망 모형에 다차원 데이터를 1차원으로 변환해주는 층을 추가한다.('완전 연결'된 결합 은닉층으로 출력하는 역할)\n",
    "\n",
    "#3. Conv2D\n",
    "#- 인공신경망 모형에 합성곱층을 생성한다.(데이터의 특성 정보를 추출·축소하는 역할)\n",
    "#\t* 주요 파라미터\n",
    "#\t- filters: 필터(커널)의 개수.\n",
    "#\t- kernel_size: 필터(커널)의 크기.\n",
    "#\t- strides: 스트라이드(필터가 이동하는 간격) 값.\n",
    "#\t- padding: 패딩 적용 방법.(\"Same\" -> 제로 패딩)\n",
    "#\t- activation: 활성화 함수.\n",
    "#\t- input_shape: 입력 특성 형태.(최초 은닉층 외에는 기재 X)\n",
    "\n",
    "#4. MaxPooling2D\n",
    "#- 인공신경망 모형에 풀링층(출력의 크기를 줄이는 역할)을 생성한다.(최대 풀링 방식)\n",
    "#- pool_size: 적용할 풀링 크기."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10233 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'C:\\\\Users\\\\PARK SUNHWAN\\\\Desktop\\\\DS\\\\DF902\\\\DF902_Data\\\\DF902_Data_Galaxy_Resize\\\\train_galaxy',\n",
    "    target_size=(50, 50),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=27,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = val_datagen.flow_from_directory(\n",
    "    'C:\\\\Users\\\\PARK SUNHWAN\\\\Desktop\\\\DS\\\\DF902\\\\DF902_Data\\\\DF902_Data_Galaxy_Resize\\\\val_galaxy',\n",
    "    target_size=(50, 50),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=3,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'C:\\\\Users\\\\PARK SUNHWAN\\\\Desktop\\\\DS\\\\DF902\\\\DF902_Data\\\\DF902_Data_Galaxy_Resize\\\\test_galaxy',\n",
    "    target_size=(50, 50),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=3,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = flow_from_directory\n",
    "# B = target_size\n",
    "# C = batch_size\n",
    "# D = class_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu',\\\n",
    "                 input_shape=(50, 50, 1)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Relu 활성함수\n",
    "# - Rectified Linear Unit\n",
    "# - 입력값 < 0이면 0, 입력값 > 0이면 입력값을 그대로(linear) 출력.\n",
    "# - 기존 활성함수로 많이 사용되던 sigmoid가 가진 문제 Gradient Vanishing을 해결하며 등장한 활성함수.\n",
    "#     *Gradient Vanishing: 뉴럴 네트워크에서, 신경망이 깊어질수록 학습이 어려워지는 문제가 있어, 이를 해결하기 위해 전체 레이어를 한 번 계산한 후, 그 값을 역으로 다시 계산하는 Back Propagation을 사용한다.\n",
    "#                          그런데 sigmoid 함수를 사용할 경우, 레이어가 깊어질수록 Back Propagation이 제대로 작동하지 않는 현상(값을 뒤에서 앞으로 전달할 때 희석이 되는 현상)이 발생했고, 이 현상을 Gradient Vanishing 이라고 한다.\n",
    "# - 2가지 이상의 레이블 분류하는 경우 주로 사용!(sigmoid는 Gradient Vanishing 때문에 잘 사용 X)\n",
    "# 뉴럴 네트워크의 은닉층 활성화 함수로 주로 사용.\n",
    "\n",
    "# 2. softmax 활성함수\n",
    "# - sigmoid(or Relu) 함수가 이산 분류(결과값에 따라 참 또는 거짓을 나타내는) 함수라면, softmax 함수는 여러 레이블 분류에 대한 확률 값을 출력할 수 있는 함수이다. 분류의 수 n에 대해, P(1) + P(2) + ... + P(n) = 1을 가지는 Pn값을 출력한다.\n",
    "# - 3가지 이상의 레이블 분류하는 경우 주로 사용!\n",
    "# - 뉴럴 네트워크 가장 마지막 부분에 주로 사용!(결과를 확률값을로 해석하기 위해)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "# 1. loss\n",
    "# - 현재 모델의 가중치 세트를 평가하는 데 사용하는 손실 함수(cost function).\n",
    "# - 현재 3가지 이상의 레이블을 분류하는 다중 클래스 문제이므로 'categorical_crossentrpy' 사용.\n",
    "\n",
    "# 2. optimizer\n",
    "# - 모델의 최적의 가중치(weight parameter)를 탐색하는 데 사용되는 최적화 알고리즘.\n",
    "# - 최적을 값을 찾아가는 데 '방향성', '스탭사이즈' 모두를 고려하는 효율적인 Gradient Descent Optimizer 'adam' 사용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "379/379 [==============================] - 101s 267ms/step - loss: 0.6975 - acc: 0.6999 - val_loss: 0.5589 - val_acc: 0.7817\n",
      "Epoch 2/10\n",
      "379/379 [==============================] - 92s 241ms/step - loss: 0.5684 - acc: 0.7721 - val_loss: 0.5538 - val_acc: 0.7883\n",
      "Epoch 3/10\n",
      "379/379 [==============================] - 95s 252ms/step - loss: 0.5199 - acc: 0.7876 - val_loss: 0.5495 - val_acc: 0.7850\n",
      "Epoch 4/10\n",
      "379/379 [==============================] - 88s 233ms/step - loss: 0.4592 - acc: 0.8119 - val_loss: 0.5285 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "379/379 [==============================] - 89s 234ms/step - loss: 0.4026 - acc: 0.8375 - val_loss: 0.5359 - val_acc: 0.8083\n",
      "Epoch 6/10\n",
      "379/379 [==============================] - 92s 242ms/step - loss: 0.3455 - acc: 0.8634 - val_loss: 0.5509 - val_acc: 0.8150\n",
      "Epoch 7/10\n",
      "379/379 [==============================] - 88s 233ms/step - loss: 0.2956 - acc: 0.8857 - val_loss: 0.6722 - val_acc: 0.8033\n",
      "Epoch 8/10\n",
      "379/379 [==============================] - 89s 236ms/step - loss: 0.2430 - acc: 0.9052 - val_loss: 0.7042 - val_acc: 0.8067\n",
      "Epoch 9/10\n",
      "379/379 [==============================] - 88s 233ms/step - loss: 0.1901 - acc: 0.9264 - val_loss: 0.7639 - val_acc: 0.7900\n",
      "Epoch 10/10\n",
      "379/379 [==============================] - 90s 236ms/step - loss: 0.1529 - acc: 0.9423 - val_loss: 0.8920 - val_acc: 0.8017\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(train_generator, steps_per_epoch=379, epochs=10, validation_data=val_generator, validation_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Evaluate--\n",
      "acc: 79.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"--Evaluate--\")\n",
    "scores = model.evaluate_generator(test_generator, steps=200)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A: fit_generator\n",
    "# B: 9(# of traning data / batch size => 10,233 / 1137)\n",
    "    # * 트레이닝 데이터 셋 크기에 비해 기존 배치 사이즈(3)가 너무 작아, steps 수가 지나치게 커짐 => 시간 너무 오래 걸림, overfitting 문제 확인 => 배치 사이즈 수정(3 -> 1137)\n",
    "# C: 200(# of validation data / batch size => 600 / 3)\n",
    "# D: evaluate_generator\n",
    "# E: 200(# of test data / batch size => 600 / 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 은하를 Edge / Smooth / Spiral 세 종류로 분류하는 것은, 오로지 각 은하의 '형태'를 기준으로 한다.\n",
    "# 따라서, 은하 분류 모델을 학습시킬 때 은하 사진의 RGB data를 사용할 필요가 없다.(Grayscale data 사용!)\n",
    "# input data의 불필요한 feature를 줄이면서, over fitting 문제를 어느 정도 예방할 수 있기 때문에, \n",
    "# 같은 조건일 때 Grayscale 활용한 모델이 더 정확도가 높을 것이다.\n",
    "\n",
    "# 개념적으로는 이렇게 생각해봤는데...\n",
    "# RGB data 사용한 모델과 Grayscale data 사용한 모델의 정확도가 크게 차이가 나질 않아서 맞는 건지는 잘 모르겠습니다 ㅠ_ㅠ\n",
    "\n",
    "# 다만 over fitting 문제를 해결하기 위해 epochs을 적정 수준으로 낮추고, Dropout layer을 추가했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
