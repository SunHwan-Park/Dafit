{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF902_SunHwanPark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Dense 레이어\n",
    "#- 인공신경망 모형에 입력과 출력이 모두 연결된 은닉층(들)과, 출력층을 생성한다.(add 함수로 모델에 추가)\n",
    "#\t* 주요 파라미터\n",
    "#\t- units: 해당 층에 배치할 노드 수\n",
    "#\t- input_dim: 입력 특성의 수, 즉 입력 노드의 개수이다.(최초 은닉층 외에는 기재 X)\n",
    "#\t- kernel_initializer: 가중치들의 초기화, 설정 방법.\n",
    "#\t- activation: 활성화 함수.\n",
    "\n",
    "#2. Flatten 레이어\n",
    "#- 인공신경망 모형에 다차원 데이터를 1차원으로 변환해주는 층을 추가한다.('완전 연결'된 결합 은닉층으로 출력하는 역할)\n",
    "\n",
    "#3. Conv2D\n",
    "#- 인공신경망 모형에 합성곱층을 생성한다.(데이터의 특성 정보를 추출·축소하는 역할)\n",
    "#\t* 주요 파라미터\n",
    "#\t- filters: 필터(커널)의 개수.\n",
    "#\t- kernel_size: 필터(커널)의 크기.\n",
    "#\t- strides: 스트라이드(필터가 이동하는 간격) 값.\n",
    "#\t- padding: 패딩 적용 방법.(\"Same\" -> 제로 패딩)\n",
    "#\t- activation: 활성화 함수.\n",
    "#\t- input_shape: 입력 특성 형태.(최초 은닉층 외에는 기재 X)\n",
    "\n",
    "#4. MaxPooling2D\n",
    "#- 인공신경망 모형에 풀링층(출력의 크기를 줄이는 역할)을 생성한다.(최대 풀링 방식)\n",
    "#- pool_size: 적용할 풀링 크기."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10233 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'C:\\\\Users\\\\PARK SUNHWAN\\\\Desktop\\\\DS\\\\DF902\\\\DF902_Data\\\\DF902_Data_Galaxy_Resize\\\\train_galaxy',\n",
    "    target_size=(50, 50),\n",
    "    batch_size=1137,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = val_datagen.flow_from_directory(\n",
    "    'C:\\\\Users\\\\PARK SUNHWAN\\\\Desktop\\\\DS\\\\DF902\\\\DF902_Data\\\\DF902_Data_Galaxy_Resize\\\\val_galaxy',\n",
    "    target_size=(50, 50),\n",
    "    batch_size=3,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'C:\\\\Users\\\\PARK SUNHWAN\\\\Desktop\\\\DS\\\\DF902\\\\DF902_Data\\\\DF902_Data_Galaxy_Resize\\\\test_galaxy',\n",
    "    target_size=(50, 50),\n",
    "    batch_size=3,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = flow_from_directory\n",
    "# B = target_size\n",
    "# C = batch_size\n",
    "# D = class_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu',\\\n",
    "                 input_shape=(50, 50, 3)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Relu 활성함수\n",
    "# - Rectified Linear Unit\n",
    "# - 입력값 < 0이면 0, 입력값 > 0이면 입력값을 그대로(linear) 출력.\n",
    "# - 기존 활성함수로 많이 사용되던 sigmoid가 가진 문제 Gradient Vanishing을 해결하며 등장한 활성함수.\n",
    "#     *Gradient Vanishing: 뉴럴 네트워크에서, 신경망이 깊어질수록 학습이 어려워지는 문제가 있어, 이를 해결하기 위해 전체 레이어를 한 번 계산한 후, 그 값을 역으로 다시 계산하는 Back Propagation을 사용한다.\n",
    "#                          그런데 sigmoid 함수를 사용할 경우, 레이어가 깊어질수록 Back Propagation이 제대로 작동하지 않는 현상(값을 뒤에서 앞으로 전달할 때 희석이 되는 현상)이 발생했고, 이 현상을 Gradient Vanishing 이라고 한다.\n",
    "# - 2가지 이상의 레이블 분류하는 경우 주로 사용!(sigmoid는 Gradient Vanishing 때문에 잘 사용 X)\n",
    "# 뉴럴 네트워크의 은닉층 활성화 함수로 주로 사용.\n",
    "\n",
    "# 2. softmax 활성함수\n",
    "# - sigmoid(or Relu) 함수가 이산 분류(결과값에 따라 참 또는 거짓을 나타내는) 함수라면, softmax 함수는 여러 레이블 분류에 대한 확률 값을 출력할 수 있는 함수이다. 분류의 수 n에 대해, P(1) + P(2) + ... + P(n) = 1을 가지는 Pn값을 출력한다.\n",
    "# - 3가지 이상의 레이블 분류하는 경우 주로 사용!\n",
    "# - 뉴럴 네트워크 가장 마지막 부분에 주로 사용!(결과를 확률값을로 해석하기 위해)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "# 1. loss\n",
    "# - 현재 모델의 가중치 세트를 평가하는 데 사용하는 손실 함수(cost function).\n",
    "# - 현재 3가지 이상의 레이블을 분류하는 다중 클래스 문제이므로 'categorical_crossentrpy' 사용.\n",
    "\n",
    "# 2. optimizer\n",
    "# - 모델의 최적의 가중치(weight parameter)를 탐색하는 데 사용되는 최적화 알고리즘.\n",
    "# - 최적을 값을 찾아가는 데 '방향성', '스탭사이즈' 모두를 고려하는 효율적인 Gradient Descent Optimizer 'adam' 사용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.9960 - acc: 0.4764 - val_loss: 0.9607 - val_acc: 0.5250\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 51s 6s/step - loss: 0.8129 - acc: 0.6705 - val_loss: 0.8295 - val_acc: 0.6700\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 51s 6s/step - loss: 0.6955 - acc: 0.7265 - val_loss: 0.6845 - val_acc: 0.7133\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.6183 - acc: 0.7563 - val_loss: 0.5639 - val_acc: 0.7767\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.5736 - acc: 0.7680 - val_loss: 0.5171 - val_acc: 0.8067\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.5311 - acc: 0.7899 - val_loss: 0.5132 - val_acc: 0.8083\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.5099 - acc: 0.7964 - val_loss: 0.4682 - val_acc: 0.8150\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.4969 - acc: 0.8029 - val_loss: 0.5015 - val_acc: 0.7983\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.4775 - acc: 0.8111 - val_loss: 0.4554 - val_acc: 0.8250\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.4609 - acc: 0.8181 - val_loss: 0.4469 - val_acc: 0.8233\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.4492 - acc: 0.8232 - val_loss: 0.4349 - val_acc: 0.8417\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 51s 6s/step - loss: 0.4404 - acc: 0.8260 - val_loss: 0.4707 - val_acc: 0.8117\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.4294 - acc: 0.8284 - val_loss: 0.4599 - val_acc: 0.8167\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 52s 6s/step - loss: 0.4255 - acc: 0.8324 - val_loss: 0.4790 - val_acc: 0.8133\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.4161 - acc: 0.8380 - val_loss: 0.4722 - val_acc: 0.8150\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 51s 6s/step - loss: 0.3921 - acc: 0.8463 - val_loss: 0.4266 - val_acc: 0.8267\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 52s 6s/step - loss: 0.3872 - acc: 0.8484 - val_loss: 0.4250 - val_acc: 0.8267\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.3732 - acc: 0.8540 - val_loss: 0.4371 - val_acc: 0.8267\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.3790 - acc: 0.8475 - val_loss: 0.4351 - val_acc: 0.8300\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.3623 - acc: 0.8564 - val_loss: 0.4261 - val_acc: 0.8267\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.3578 - acc: 0.8604 - val_loss: 0.4438 - val_acc: 0.8183\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.3462 - acc: 0.8674 - val_loss: 0.5086 - val_acc: 0.7983\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 56s 6s/step - loss: 0.3394 - acc: 0.8676 - val_loss: 0.5101 - val_acc: 0.8000\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.3327 - acc: 0.8724 - val_loss: 0.4561 - val_acc: 0.8200\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.3248 - acc: 0.8734 - val_loss: 0.4292 - val_acc: 0.8367\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.3096 - acc: 0.8805 - val_loss: 0.4366 - val_acc: 0.8267\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 62s 7s/step - loss: 0.3044 - acc: 0.8795 - val_loss: 0.4721 - val_acc: 0.8117\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 62s 7s/step - loss: 0.2984 - acc: 0.8876 - val_loss: 0.4590 - val_acc: 0.8167\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 60s 7s/step - loss: 0.2757 - acc: 0.8995 - val_loss: 0.4808 - val_acc: 0.8200\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 57s 6s/step - loss: 0.2642 - acc: 0.9008 - val_loss: 0.4445 - val_acc: 0.8250\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 63s 7s/step - loss: 0.2668 - acc: 0.8988 - val_loss: 0.5012 - val_acc: 0.8150\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 61s 7s/step - loss: 0.2691 - acc: 0.8970 - val_loss: 0.4325 - val_acc: 0.8467\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 60s 7s/step - loss: 0.2597 - acc: 0.9011 - val_loss: 0.4448 - val_acc: 0.8383\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.2413 - acc: 0.9110 - val_loss: 0.5026 - val_acc: 0.8233\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 63s 7s/step - loss: 0.2222 - acc: 0.9217 - val_loss: 0.4819 - val_acc: 0.8267\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 60s 7s/step - loss: 0.2162 - acc: 0.9235 - val_loss: 0.5234 - val_acc: 0.8100\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.2127 - acc: 0.9239 - val_loss: 0.4770 - val_acc: 0.8167\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 55s 6s/step - loss: 0.2028 - acc: 0.9285 - val_loss: 0.5869 - val_acc: 0.7967\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 52s 6s/step - loss: 0.2218 - acc: 0.9137 - val_loss: 0.4818 - val_acc: 0.8100\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.1918 - acc: 0.9315 - val_loss: 0.5284 - val_acc: 0.8100\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.1796 - acc: 0.9389 - val_loss: 0.5274 - val_acc: 0.8183\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.1710 - acc: 0.9412 - val_loss: 0.5476 - val_acc: 0.8200\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 51s 6s/step - loss: 0.1735 - acc: 0.9408 - val_loss: 0.5227 - val_acc: 0.8200\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.1522 - acc: 0.9500 - val_loss: 0.5402 - val_acc: 0.8217\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.1716 - acc: 0.9379 - val_loss: 0.5289 - val_acc: 0.8150\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.1602 - acc: 0.9437 - val_loss: 0.5843 - val_acc: 0.7950\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 52s 6s/step - loss: 0.1400 - acc: 0.9556 - val_loss: 0.5318 - val_acc: 0.8300\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.1261 - acc: 0.9606 - val_loss: 0.5516 - val_acc: 0.8233\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 51s 6s/step - loss: 0.1177 - acc: 0.9653 - val_loss: 0.5495 - val_acc: 0.8300\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.1174 - acc: 0.9635 - val_loss: 0.5634 - val_acc: 0.8233\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(train_generator, steps_per_epoch=9, epochs=50,\n",
    "             validation_data=val_generator, validation_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Evaluate--\n",
      "acc: 82.33%\n"
     ]
    }
   ],
   "source": [
    "print(\"--Evaluate--\")\n",
    "scores = model.evaluate_generator(test_generator, steps=200)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A: fit_generator\n",
    "# B: 9(# of traning data / batch size => 10,233 / 1137)\n",
    "    # * 트레이닝 데이터 셋 크기에 비해 기존 배치 사이즈(3)가 너무 작아, steps 수가 지나치게 커짐 => 시간 너무 오래 걸림, overfitting 문제 확인 => 배치 사이즈 수정(3 -> 1137)\n",
    "# C: 200(# of validation data / batch size => 600 / 3)\n",
    "# D: evaluate_generator\n",
    "# E: 200(# of test data / batch size => 600 / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
